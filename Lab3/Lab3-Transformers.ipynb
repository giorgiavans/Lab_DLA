{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e91cdb-4693-4632-b7aa-f37eec027131",
   "metadata": {},
   "source": [
    "## Working with Transformers in the HuggingFace Ecosystem\n",
    "\n",
    "In this laboratory exercise we will learn how to work with the HuggingFace ecosystem to adapt models to new tasks. As you will see, much of what is required is *investigation* into the inner-workings of the HuggingFace abstractions. With a little work, a little trial-and-error, it is fairly easy to get a working adaptation pipeline up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e556105-269f-43e3-8933-227269afb9ea",
   "metadata": {},
   "source": [
    "### Exercise 1: Sentiment Analysis (warm up)\n",
    "\n",
    "In this first exercise we will start from a pre-trained BERT transformer and build up a model able to perform text sentiment analysis. Transformers are complex beasts, so we will build up our pipeline in several explorative and incremental steps.\n",
    "\n",
    "#### Exercise 1.1: Dataset Splits and Pre-trained model\n",
    "There are a many sentiment analysis datasets, but we will use one of the smallest ones available: the [Cornell Rotten Tomatoes movie review dataset](cornell-movie-review-data/rotten_tomatoes), which consists of 5,331 positive and 5,331 negative processed sentences from the Rotten Tomatoes movie reviews.\n",
    "\n",
    "**Your first task**: Load the dataset and figure out what splits are available and how to get them. Spend some time exploring the dataset to see how it is organized. Note that we will be using the [HuggingFace Datasets](https://huggingface.co/docs/datasets/en/index) library for downloading, accessing, splitting, and batching data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923ff132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split disponibili per il dataset 'rotten_tomatoes': ['train', 'validation', 'test']\n",
      "------------------------------\n",
      "Caricamento del dataset 'rotten_tomatoes'...\n",
      "Dataset caricato con successo!\n",
      "------------------------------\n",
      "Esplorazione del dataset:\n",
      "\n",
      "Split caricati nel DatasetDict: dict_keys(['train', 'validation', 'test'])\n",
      "\n",
      "--- Split: 'train' ---\n",
      "Numero di esempi nello split 'train': 8530\n",
      "Features dello split 'train':\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
      "Primi 3 esempi dallo split 'train':\n",
      "  Esempio 0: {'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}\n",
      "  Esempio 1: {'text': 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'label': 1}\n",
      "  Esempio 2: {'text': 'effective but too-tepid biopic', 'label': 1}\n",
      "  Nomi delle etichette (labels) in 'train': ['neg', 'pos']\n",
      "\n",
      "--- Split: 'validation' ---\n",
      "Numero di esempi nello split 'validation': 1066\n",
      "Features dello split 'validation':\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
      "Primi 3 esempi dallo split 'validation':\n",
      "  Esempio 0: {'text': 'compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .', 'label': 1}\n",
      "  Esempio 1: {'text': 'the soundtrack alone is worth the price of admission .', 'label': 1}\n",
      "  Esempio 2: {'text': 'rodriguez does a splendid job of racial profiling hollywood style--casting excellent latin actors of all ages--a trend long overdue .', 'label': 1}\n",
      "  Nomi delle etichette (labels) in 'validation': ['neg', 'pos']\n",
      "\n",
      "--- Split: 'test' ---\n",
      "Numero di esempi nello split 'test': 1066\n",
      "Features dello split 'test':\n",
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
      "Primi 3 esempi dallo split 'test':\n",
      "  Esempio 0: {'text': 'lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'label': 1}\n",
      "  Esempio 1: {'text': 'consistently clever and suspenseful .', 'label': 1}\n",
      "  Esempio 2: {'text': 'it\\'s like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .', 'label': 1}\n",
      "  Nomi delle etichette (labels) in 'test': ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_split_names\n",
    "\n",
    "dataset_name = \"rotten_tomatoes\"\n",
    "\n",
    "# Questo è utile per sapere in anticipo quali split sono presenti\n",
    "try:\n",
    "    available_splits = get_dataset_split_names(dataset_name)\n",
    "    print(f\"Split disponibili per il dataset '{dataset_name}': {available_splits}\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel recuperare i nomi degli split per '{dataset_name}': {e}\")\n",
    "    print(\"Potrebbe essere necessario caricare il dataset prima di poter ispezionare gli split, o il dataset potrebbe non avere split predefiniti.\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(f\"Caricamento del dataset '{dataset_name}'...\")\n",
    "dataset = load_dataset(dataset_name)\n",
    "print(\"Dataset caricato con successo!\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"Esplorazione del dataset:\")\n",
    "\n",
    "print(f\"\\nSplit caricati nel DatasetDict: {dataset.keys()}\")\n",
    "\n",
    "# Iterare su ogni split e mostrare alcune informazioni\n",
    "for split_name in dataset.keys():\n",
    "    print(f\"\\n--- Split: '{split_name}' ---\")\n",
    "    current_split = dataset[split_name]\n",
    "\n",
    "    print(f\"Numero di esempi nello split '{split_name}': {len(current_split)}\")\n",
    "\n",
    "    # Mostra la struttura delle features (colonne)\n",
    "    print(f\"Features dello split '{split_name}':\")\n",
    "    print(current_split.features)\n",
    "\n",
    "    # Mostra i primi 3 esempi di questo split\n",
    "    print(f\"Primi 3 esempi dallo split '{split_name}':\")\n",
    "    for i in range(min(3, len(current_split))): \n",
    "        print(f\"  Esempio {i}: {current_split[i]}\")\n",
    "\n",
    "    if 'label' in current_split.features:\n",
    "        label_feature = current_split.features['label']\n",
    "        if hasattr(label_feature, 'names'): \n",
    "            print(f\"  Nomi delle etichette (labels) in '{split_name}': {label_feature.names}\")\n",
    "        else:\n",
    "            print(f\"  Tipo di etichetta (label) in '{split_name}': {label_feature.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f50a0-0af4-4bdd-9a60-bab26f126c14",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: A Pre-trained BERT and Tokenizer\n",
    "\n",
    "The model we will use is a *very* small BERT transformer called [Distilbert](https://huggingface.co/distilbert/distilbert-base-uncased) this model was trained (using self-supervised learning) on the same corpus as BERT but using the full BERT base model as a *teacher*.\n",
    "\n",
    "**Your next task**: Load the Distilbert model and corresponding tokenizer. Use the tokenizer on a few samples from the dataset and pass the tokens through the model to see what outputs are provided. I suggest you use the [`AutoModel`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html) class (and the `from_pretrained()` method) to load the model and `AutoTokenizer` to load the tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del tokenizer per 'distilbert-base-uncased'...\n",
      "Tokenizer caricato con successo!\n",
      "Caricamento del modello 'distilbert-base-uncased'...\n",
      "Modello caricato con successo!\n",
      "------------------------------\n",
      "Test di tokenizzazione e passaggio al modello con i seguenti esempi:\n",
      "  Esempio 1: \"the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\"\n",
      "  Esempio 2: \"the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\"\n",
      "  Esempio 3: \"This movie was absolutely fantastic! Highly recommended.\"\n",
      "  Esempio 4: \"I regret wasting my time on this dreadful film.\"\n",
      "------------------------------\n",
      "Tokenizzazione degli esempi...\n",
      "\n",
      "Output del tokenizer per il primo esempio (sample_texts[0]):\n",
      "Input IDs: tensor([  101,  1996,  2600,  2003, 16036,  2000,  2022,  1996,  7398,  2301,\n",
      "         1005,  1055,  2047,  1000, 16608,  1000,  1998,  2008,  2002,  1005,\n",
      "         1055,  2183,  2000,  2191,  1037, 17624,  2130,  3618,  2084,  7779,\n",
      "        29058,  8625, 13327,  1010,  3744,  1011, 18856, 19513,  3158,  5477,\n",
      "         4168,  2030,  7112, 16562,  2140,  1012,   102,     0,     0,     0,\n",
      "            0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0])\n",
      "\n",
      "Decodifica dei primi Input IDs per visualizzare i token:\n",
      "Testo originale: \"the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\"\n",
      "Token decodificati: \"[CLS] the rock is destined to be the 21st century ' s new \" conan \" and that he ' s going to make a splash even greater than arnold schwarzenegger, jean - claud van damme or steven segal. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\"\n",
      "------------------------------\n",
      "Passaggio dei token attraverso il modello DistilBERT...\n",
      "Output del modello generati con successo!\n",
      "\n",
      "Struttura degli output del modello:\n",
      "BaseModelOutput(last_hidden_state=tensor([[[-0.0332, -0.0168,  0.0194,  ...,  0.0476,  0.5834,  0.3036],\n",
      "         [-0.0235, -0.0555, -0.3638,  ...,  0.1877,  0.5781, -0.1577],\n",
      "         [-0.0516, -0.1014, -0.1511,  ...,  0.1503,  0.2649, -0.1575],\n",
      "         ...,\n",
      "         [ 0.3688, -0.1147,  0.8428,  ..., -0.0708, -0.0178, -0.2516],\n",
      "         [ 0.0654, -0.0206,  0.1889,  ...,  0.1159,  0.2323, -0.2404],\n",
      "         [ 0.0373, -0.0104,  0.1203,  ...,  0.1049,  0.2852, -0.3035]],\n",
      "\n",
      "        [[-0.2062, -0.0490, -0.4036,  ..., -0.1186,  0.6141,  0.3919],\n",
      "         [-0.4361, -0.1647, -0.3533,  ...,  0.1086,  0.9478, -0.0272],\n",
      "         [-0.1164,  0.1690,  0.2698,  ..., -0.1971,  0.4372,  0.2527],\n",
      "         ...,\n",
      "         [-0.2341,  0.4810, -0.2634,  ..., -0.3397,  0.2567,  0.1274],\n",
      "         [ 0.7139,  0.0574, -0.3260,  ...,  0.2041, -0.3800, -0.3343],\n",
      "         [ 0.5649,  0.2806, -0.0295,  ...,  0.1297, -0.3160, -0.1874]],\n",
      "\n",
      "        [[ 0.0432, -0.1823,  0.1302,  ..., -0.2466,  0.4565,  0.2050],\n",
      "         [-0.1186, -0.4483,  0.0269,  ..., -0.4316,  1.1597, -0.0252],\n",
      "         [ 0.4478, -0.3128, -0.1083,  ..., -0.1622,  0.3151, -0.4454],\n",
      "         ...,\n",
      "         [ 0.2223, -0.2755,  0.1666,  ...,  0.1257,  0.1423, -0.1665],\n",
      "         [ 0.1823, -0.2852,  0.2227,  ...,  0.1228,  0.1629, -0.0951],\n",
      "         [ 0.1363, -0.2828,  0.2259,  ...,  0.0826,  0.1911, -0.0865]],\n",
      "\n",
      "        [[ 0.3097,  0.1980, -0.0220,  ...,  0.0941,  0.3865,  0.3149],\n",
      "         [ 0.6103,  0.6293, -0.0890,  ...,  0.1226,  0.6335,  0.4346],\n",
      "         [ 0.1574,  0.6221,  0.6439,  ...,  0.1787,  0.3887,  0.5076],\n",
      "         ...,\n",
      "         [ 0.3969,  0.1561, -0.0335,  ..., -0.1347,  0.3975, -0.2709],\n",
      "         [ 0.4818,  0.2632, -0.1911,  ...,  0.4035,  0.1000, -0.0418],\n",
      "         [ 0.4808,  0.2921, -0.0695,  ...,  0.4399,  0.1044, -0.0341]]]), hidden_states=None, attentions=None)\n",
      "\n",
      "Shape di 'last_hidden_state' (batch_size, sequence_length, hidden_size):\n",
      "torch.Size([4, 52, 768])\n",
      "\n",
      "Output nascosto (embedding) per il token [CLS] del primo esempio:\n",
      "tensor([-0.0332, -0.0168,  0.0194, -0.0257, -0.1380, -0.3962,  0.3830,  0.5118,\n",
      "         0.0231, -0.0555])\n",
      "\n",
      "Task completato: Tokenizer e Modello caricati, esempi tokenizzati e passati al modello.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset \n",
    "\n",
    "# 'uncased' significa che il modello non distingue tra maiuscole e minuscole \n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Caricare il tokenizer pre-addestrato\n",
    "print(f\"Caricamento del tokenizer per '{model_name}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"Tokenizer caricato con successo!\")\n",
    "\n",
    "# Caricare il modello pre-addestrato\n",
    "# AutoModel per caricare il modello base.\n",
    "print(f\"Caricamento del modello '{model_name}'...\")\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "print(\"Modello caricato con successo!\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(\"rotten_tomatoes\")\n",
    "    sample_texts = [\n",
    "        dataset['train'][0]['text'], # Esempio positivo dal training set\n",
    "        dataset['train'][1]['text'], # Esempio negativo dal training set\n",
    "        \"This movie was absolutely fantastic! Highly recommended.\", # Un esempio positivo\n",
    "        \"I regret wasting my time on this dreadful film.\" # Un esempio negativo\n",
    "    ]\n",
    "except NameError:\n",
    "    print(\"Dataset 'rotten_tomatoes' non trovato. Si prega di caricarlo prima di eseguire questa sezione o di fornire esempi manuali.\")\n",
    "    sample_texts = [\n",
    "        \"This movie was a cinematic masterpiece.\",\n",
    "        \"Absolutely the worst film I've seen this year.\",\n",
    "        \"A truly enjoyable experience.\",\n",
    "        \"Boring and uninspired.\"\n",
    "    ]\n",
    "\n",
    "print(\"Test di tokenizzazione e passaggio al modello con i seguenti esempi:\")\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"  Esempio {i+1}: \\\"{text}\\\"\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Tokenizzare i campioni\n",
    "# Il tokenizer converte il testo in input_ids, attention_mask, e (opzionalmente) token_type_ids.\n",
    "# return_tensors='pt' restituisce i tensori PyTorch, necessari per il modello.\n",
    "# truncation=True tronca le sequenze più lunghe della massima lunghezza supportata dal modello (512 per BERT/DistilBERT).\n",
    "# padding=True aggiunge padding alle sequenze più corte per raggiungere la massima lunghezza o la lunghezza della sequenza più lunga nel batch.\n",
    "print(\"Tokenizzazione degli esempi...\")\n",
    "tokenized_inputs = tokenizer(sample_texts,\n",
    "                             padding=True,\n",
    "                             truncation=True,\n",
    "                             return_tensors='pt') # 'pt' for PyTorch tensors\n",
    "\n",
    "print(\"\\nOutput del tokenizer per il primo esempio (sample_texts[0]):\")\n",
    "print(\"Input IDs:\", tokenized_inputs['input_ids'][0])\n",
    "print(\"Attention Mask:\", tokenized_inputs['attention_mask'][0])\n",
    "\n",
    "print(\"\\nDecodifica dei primi Input IDs per visualizzare i token:\")\n",
    "decoded_tokens = tokenizer.decode(tokenized_inputs['input_ids'][0])\n",
    "print(f\"Testo originale: \\\"{sample_texts[0]}\\\"\")\n",
    "print(f\"Token decodificati: \\\"{decoded_tokens}\\\"\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Passare i token attraverso il modello\n",
    "print(\"Passaggio dei token attraverso il modello DistilBERT...\")\n",
    "with_no_grad = True # Per risparmiare memoria durante l'inferenza, non calcoliamo i gradienti\n",
    "\n",
    "if with_no_grad:\n",
    "    import torch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_inputs)\n",
    "else:\n",
    "    outputs = model(**tokenized_inputs)\n",
    "\n",
    "print(\"Output del modello generati con successo!\")\n",
    "\n",
    "# Esaminare gli output del modello\n",
    "# I modelli AutoModel restituiscono un oggetto simile a un dizionario.\n",
    "# Per DistilBERT (AutoModel), l'output principale è `last_hidden_state`.\n",
    "# Questo è l'output dell'ultimo strato del Transformer per ogni token.\n",
    "print(\"\\nStruttura degli output del modello:\")\n",
    "print(outputs)\n",
    "\n",
    "print(\"\\nShape di 'last_hidden_state' (batch_size, sequence_length, hidden_size):\")\n",
    "print(outputs.last_hidden_state.shape) # Esempio: torch.Size([4, 50, 768])\n",
    "# 4 è il numero di esempi, 50 è la lunghezza massima della sequenza dopo padding,\n",
    "# 768 è la dimensione dell'embedding nascosto di DistilBERT.\n",
    "\n",
    "print(\"\\nOutput nascosto (embedding) per il token [CLS] del primo esempio:\")\n",
    "# Il token [CLS] (Class Label) è il primo token (indice 0) nella sequenza.\n",
    "# Per compiti di classificazione di sequenza, l'embedding di [CLS] dell'ultimo strato\n",
    "# è spesso usato come rappresentazione dell'intera frase.\n",
    "print(outputs.last_hidden_state[0, 0, :10]) # Mostra i primi 10 valori dell'embedding\n",
    "\n",
    "print(\"\\nTask completato: Tokenizer e Modello caricati, esempi tokenizzati e passati al modello.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f6fd4-b80b-466d-b4ff-9aac0492c062",
   "metadata": {},
   "source": [
    "#### Exercise 1.3: A Stable Baseline\n",
    "\n",
    "In this exercise I want you to:\n",
    "1. Use Distilbert as a *feature extractor* to extract representations of the text strings from the dataset splits;\n",
    "2. Train a classifier (your choice, by an SVM from Scikit-learn is an easy choice).\n",
    "3. Evaluate performance on the validation and test splits.\n",
    "\n",
    "These results are our *stable baseline* -- the **starting** point on which we will (hopefully) improve in the next exercise.\n",
    "\n",
    "**Hint**: There are a number of ways to implement the feature extractor, but probably the best is to use a [feature extraction `pipeline`](https://huggingface.co/tasks/feature-extraction). You will need to interpret the output of the pipeline and extract only the `[CLS]` token from the *last* transformer layer. *How can you figure out which output that is?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e64af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm.auto import tqdm # Per visualizzare una barra di avanzamento durante l'estrazione delle features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90059841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'rotten_tomatoes' caricato.\n"
     ]
    }
   ],
   "source": [
    "# Caricare il dataset (se non lo hai già fatto)\n",
    "dataset_name = \"rotten_tomatoes\"\n",
    "try:\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(f\"Dataset '{dataset_name}' caricato.\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel caricare il dataset: {e}\")\n",
    "    print(\"Assicurati di aver installato la libreria 'datasets' e di essere connesso a internet.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c822d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline di feature extraction con 'distilbert-base-uncased' pronta.\n",
      "\n",
      "Estrazione delle features dai dataset split (potrebbe richiedere tempo)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8872f86e39c14eaaae8b844954539399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6e02edd1604713ae8f8657f6e99885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9f8eb28ad42d2baadc971b462203e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Struttura del dataset dopo l'estrazione delle features:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'features', 'labels'],\n",
      "        num_rows: 8530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['label', 'features', 'labels'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'features', 'labels'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "})\n",
      "Esempio di feature estratta (primo elemento dello split train): [-0.033173568546772, -0.01680893637239933, 0.01941203698515892, -0.025717880576848984, -0.1379668116569519]...\n",
      "Dimensione dell'embedding (hidden_size di DistilBERT): 768\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Inizializzare la pipeline di feature extraction\n",
    "\n",
    "feature_extractor_pipeline = pipeline(\n",
    "    \"feature-extraction\",\n",
    "    model=model_name,\n",
    "    tokenizer=model_name,\n",
    "    device=0 if np.array(0).dtype == np.int_ else -1 # Esempio per rilevare se è disponibile una GPU\n",
    ")\n",
    "print(f\"\\nPipeline di feature extraction con '{model_name}' pronta.\")\n",
    "\n",
    "# Funzione per estrarre le features (embedding del CLS token)\n",
    "def extract_cls_features(batch):\n",
    "    \n",
    "    features = feature_extractor_pipeline(batch['text'])\n",
    "\n",
    "    # Estraggo l'embedding del CLS token (il primo vettore [0][0]) per ogni esempio nel batch.\n",
    "    # Converto da lista a numpy array per comodità.\n",
    "\n",
    "    cls_embeddings = [np.array(f[0][0]) for f in features]\n",
    "    return {'features': cls_embeddings, 'labels': batch['label']}\n",
    "\n",
    "print(\"\\nEstrazione delle features dai dataset split (potrebbe richiedere tempo)...\")\n",
    "\n",
    "# Applica la funzione di estrazione features a tutti gli split del dataset\n",
    "# Uso map con batch=True per processare più esempi contemporaneamente, migliorando l'efficienza.\n",
    "# tqdm.auto è usato per visualizzare il progresso.\n",
    "extracted_dataset = dataset.map(\n",
    "    extract_cls_features,\n",
    "    batched=True,\n",
    "    batch_size=16, \n",
    "    remove_columns=['text'], \n",
    "    desc=\"Extracting features\"\n",
    ")\n",
    "\n",
    "# Verifica la struttura del dataset con le nuove features\n",
    "print(\"\\nStruttura del dataset dopo l'estrazione delle features:\")\n",
    "print(extracted_dataset)\n",
    "print(f\"Esempio di feature estratta (primo elemento dello split train): {extracted_dataset['train'][0]['features'][:5]}...\") # Mostra i primi 5 elementi dell'embedding\n",
    "print(f\"Dimensione dell'embedding (hidden_size di DistilBERT): {len(extracted_dataset['train'][0]['features'])}\") \n",
    "\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ed4eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addestramento del classificatore SVM...\n",
      "Dimensioni dei dati di training: X_train=(8530, 768), y_train=(8530,)\n",
      "Dimensioni dei dati di validation: X_val=(1066, 768), y_val=(1066,)\n",
      "Dimensioni dei dati di test: X_test=(1066, 768), y_test=(1066,)\n",
      "Classificatore SVM addestrato con successo!\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Addestrare un classificatore (SVM da Scikit-learn)\n",
    "print(\"\\nAddestramento del classificatore SVM...\")\n",
    "\n",
    "# Preparare i dati per l'SVM\n",
    "X_train = np.array(extracted_dataset['train']['features'])\n",
    "y_train = np.array(extracted_dataset['train']['labels'])\n",
    "\n",
    "X_val = np.array(extracted_dataset['validation']['features'])\n",
    "y_val = np.array(extracted_dataset['validation']['labels'])\n",
    "\n",
    "X_test = np.array(extracted_dataset['test']['features'])\n",
    "y_test = np.array(extracted_dataset['test']['labels'])\n",
    "\n",
    "print(f\"Dimensioni dei dati di training: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Dimensioni dei dati di validation: X_val={X_val.shape}, y_val={y_val.shape}\")\n",
    "print(f\"Dimensioni dei dati di test: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "\n",
    "# Inizializzare e addestrare la SVM\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classificatore SVM addestrato con successo!\")\n",
    "\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb884582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valutazione delle prestazioni...\n",
      "\n",
      "Accuracy sul set di validazione: 0.8189\n",
      "Report di classificazione sul set di validazione:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.82       533\n",
      "    positive       0.84      0.79      0.81       533\n",
      "\n",
      "    accuracy                           0.82      1066\n",
      "   macro avg       0.82      0.82      0.82      1066\n",
      "weighted avg       0.82      0.82      0.82      1066\n",
      "\n",
      "\n",
      "Accuracy sul set di test: 0.8068\n",
      "Report di classificazione sul set di test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.82      0.81       533\n",
      "    positive       0.82      0.79      0.80       533\n",
      "\n",
      "    accuracy                           0.81      1066\n",
      "   macro avg       0.81      0.81      0.81      1066\n",
      "weighted avg       0.81      0.81      0.81      1066\n",
      "\n",
      "\n",
      "Stable Baseline calcolata!\n"
     ]
    }
   ],
   "source": [
    "# Valutare le prestazioni sul validation e test splits\n",
    "print(\"\\nValutazione delle prestazioni...\")\n",
    "\n",
    "# Previsioni sul set di validazione\n",
    "y_val_pred = svm_classifier.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nAccuracy sul set di validazione: {val_accuracy:.4f}\")\n",
    "print(\"Report di classificazione sul set di validazione:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['negative', 'positive']))\n",
    "\n",
    "# Previsioni sul set di test\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nAccuracy sul set di test: {test_accuracy:.4f}\")\n",
    "print(\"Report di classificazione sul set di test:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['negative', 'positive']))\n",
    "\n",
    "print(\"\\nStable Baseline calcolata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37141d1b-935b-425c-804c-b9b487853791",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 2: Fine-tuning Distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a53f64-0238-42f2-bc20-86e51c77d2e5",
   "metadata": {},
   "source": [
    "In this exercise we will fine-tune the Distilbert model to (hopefully) improve sentiment analysis performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392b1ed-597b-4a92-90fc-10eb11eac515",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Token Preprocessing\n",
    "\n",
    "The first thing we need to do is *tokenize* our dataset splits. Our current datasets return a dictionary with *strings*, but we want *input token ids* (i.e. the output of the tokenizer). This is easy enough to do my hand, but the HugginFace `Dataset` class provides convenient, efficient, and *lazy* methods. See the documentation for [`Dataset.map`](https://huggingface.co/docs/datasets/v3.5.0/en/package_reference/main_classes#datasets.Dataset.map).\n",
    "\n",
    "**Tip**: Verify that your new datasets are returning for every element: `text`, `label`, `intput_ids`, and `attention_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6e2a95-5b08-4f81-b824-59a0fb3404e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict # Importa DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7607e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'rotten_tomatoes' caricato.\n",
      "Struttura iniziale del dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 8530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "})\n",
      "Esempio di un elemento prima della tokenizzazione:\n",
      "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# --- Caricare il dataset (se non l'hai già in memoria) ---\n",
    "dataset_name = 'rotten_tomatoes'\n",
    "try:\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(f\"Dataset '{dataset_name}' caricato.\")\n",
    "    print(\"Struttura iniziale del dataset:\")\n",
    "    print(dataset)\n",
    "    print(\"Esempio di un elemento prima della tokenizzazione:\")\n",
    "    print(dataset['train'][0])\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel caricare il dataset: {e}\")\n",
    "    print(\"Assicurati di aver installato la libreria 'datasets' e di essere connesso a internet.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef452d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caricamento del tokenizer 'distilbert-base-uncased'...\n",
      "Tokenizer caricato con successo!\n"
     ]
    }
   ],
   "source": [
    "# --- Caricare il tokenizer di DistilBERT ---\n",
    "model_name = 'distilbert-base-uncased'\n",
    "print(f\"\\nCaricamento del tokenizer '{model_name}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"Tokenizer caricato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7c14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definire la funzione di tokenizzazione ---\n",
    "def tokenize_function(examples):\n",
    "    # Il tokenizer processa il campo 'text'.\n",
    "    # padding='max_length' padderà tutte le sequenze alla lunghezza massima del modello (512 per DistilBERT)\n",
    "    # truncation=True tronca le sequenze più lunghe della lunghezza massima del modello\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df9c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applicazione della funzione di tokenizzazione al dataset (potrebbe richiedere tempo)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af3a48a946346c6b27fbc620955966f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset tokenizzato e trasformato.\n",
      "Struttura del dataset dopo la tokenizzazione:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 8530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# --- Applicare la funzione di tokenizzazione a tutti gli split del dataset ---\n",
    "print(\"\\nApplicazione della funzione di tokenizzazione al dataset (potrebbe richiedere tempo)...\")\n",
    "# Usiamo batched=True per processare più esempi contemporaneamente, il che è più efficiente.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"\\nDataset tokenizzato e trasformato.\")\n",
    "print(\"Struttura del dataset dopo la tokenizzazione:\")\n",
    "print(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38bd1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifica delle colonne del primo elemento dello split 'train':\n",
      "Contiene 'text': True\n",
      "Contiene 'label': True\n",
      "Contiene 'input_ids': True\n",
      "Contiene 'attention_mask': True\n",
      "\n",
      "Esempio del primo elemento tokenizzato dello split 'train':\n",
      "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1, 'input_ids': [101, 1996, 2600, 2003, 16036, 2000, 2022, 1996, 7398, 2301, 1005, 1055, 2047, 1000, 16608, 1000, 1998, 2008, 2002, 1005, 1055, 2183, 2000, 2191, 1037, 17624, 2130, 3618, 2084, 7779, 29058, 8625, 13327, 1010, 3744, 1011, 18856, 19513, 3158, 5477, 4168, 2030, 7112, 16562, 2140, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "Testo decodificato (dai primi 50 input_ids): [CLS] the rock is destined to be the 21st century ' s new \" conan \" and that he ' s going to make a splash even greater than arnold schwarzenegger, jean - claud van damme or steven segal. [SEP] [PAD] [PAD] [PAD]...\n"
     ]
    }
   ],
   "source": [
    "# --- Verificare che i nuovi dataset restituiscano le colonne desiderate ---\n",
    "print(\"\\nVerifica delle colonne del primo elemento dello split 'train':\")\n",
    "first_train_element = tokenized_datasets['train'][0]\n",
    "print(f\"Contiene 'text': {'text' in first_train_element}\")\n",
    "print(f\"Contiene 'label': {'label' in first_train_element}\")\n",
    "print(f\"Contiene 'input_ids': {'input_ids' in first_train_element}\")\n",
    "print(f\"Contiene 'attention_mask': {'attention_mask' in first_train_element}\")\n",
    "\n",
    "# Esempio completo di un elemento tokenizzato\n",
    "print(\"\\nEsempio del primo elemento tokenizzato dello split 'train':\")\n",
    "print(first_train_element)\n",
    "# Decodificare gli input_ids per vedere il testo originale ricostruito (utile per debug)\n",
    "print(f\"\\nTesto decodificato (dai primi 50 input_ids): {tokenizer.decode(first_train_element['input_ids'][:50])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a80de2-83c9-4c12-af4e-34babe23ffd1",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Setting up the Model to be Fine-tuned\n",
    "\n",
    "In this exercise we need to prepare the base Distilbert model for fine-tuning for a *sequence classification task*. This means, at the very least, appending a new, randomly-initialized classification head connected to the `[CLS]` token of the last transformer layer. Luckily, HuggingFace already provides an `AutoModel` for just this type of instantiation: [`AutoModelForSequenceClassification`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification). You will want you instantiate one of these for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6327d73-3b71-478a-9932-bb062a650c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caricamento del modello 'distilbert-base-uncased' per la classificazione di sequenze (num_labels=2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- Caricare il modello pre-addestrato con una testa di classificazione ---\n",
    "# Sto usando DistilBERT per la classificazione di sequenze.\n",
    "\n",
    "num_labels = 2 # Per sentiment analysis: negativo/positivo\n",
    "\n",
    "print(f\"\\nCaricamento del modello '{model_name}' per la classificazione di sequenze (num_labels={num_labels})...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109f7bd-955f-4fc4-bc3e-75bd99a17adf",
   "metadata": {},
   "source": [
    "#### Exercise 2.3: Fine-tuning Distilbert\n",
    "\n",
    "Finally. In this exercise you should use a HuggingFace [`Trainer`](https://huggingface.co/docs/transformers/main/en/trainer) to fine-tune your model on the Rotten Tomatoes training split. Setting up the trainer will involve (at least):\n",
    "\n",
    "\n",
    "1. Instantiating a [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/en/main_classes/data_collator) object which is what *actually* does your batch construction (by padding all sequences to the same length).\n",
    "2. Writing an *evaluation function* that will measure the classification accuracy. This function takes a single argument which is a tuple containing `(logits, labels)` which you should use to compute classification accuracy (and maybe other metrics like F1 score, precision, recall) and return a `dict` with these metrics.  \n",
    "3. Instantiating a [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.51.1/en/main_classes/trainer#transformers.TrainingArguments) object using some reasonable defaults.\n",
    "4. Instantiating a `Trainer` object using your train and validation splits, you data collator, and function to compute performance metrics.\n",
    "5. Calling `trainer.train()`, waiting, waiting some more, and then calling `trainer.evaluate()` to see how it did.\n",
    "\n",
    "**Tip**: When prototyping this laboratory I discovered the HuggingFace [Evaluate library](https://huggingface.co/docs/evaluate/en/index) which provides evaluation metrics. However I found it to have insufferable layers of abstraction and getting actual metrics computed. I suggest just using the Scikit-learn metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab17178d-5028-47e3-af97-953e8de5aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72672ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizializzazione del DataCollatorWithPadding...\n",
      "DataCollatorWithPadding inizializzato.\n"
     ]
    }
   ],
   "source": [
    "# --- Instanziare un DataCollatorWithPadding ---\n",
    "# Questo Data Collator padderà dinamicamente le sequenze nel batch alla lunghezza massima del batch.\n",
    "print(\"\\nInizializzazione del DataCollatorWithPadding...\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"DataCollatorWithPadding inizializzato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a701a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scrivere una funzione di valutazione (compute_metrics) ---\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Funzione per calcolare le metriche di valutazione.\n",
    "    Prende un oggetto EvalPrediction (tuple di logits e labels) e restituisce un dizionario di metriche.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred # eval_pred è un tuple (logits, labels)\n",
    "\n",
    "    # Converte i logits in previsioni di classe (l'indice con il valore più alto)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Calcola l'accuratezza\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calcola precisione, recall e F1-score per ogni classe e il macro average\n",
    "    # labels=[0, 1] per assicurarsi che tutte le classi siano considerate\n",
    "    # average='binary' per il f1, precision, recall per la classe positiva (1)\n",
    "    # average='macro' per calcolare la media non pesata delle metriche per ogni classe\n",
    "    # average='weighted' per calcolare la media pesata dal numero di istanze per ogni classe\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None, labels=[0, 1])\n",
    "\n",
    "    # Crea un dizionario con tutte le metriche\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"positive_precision\": precision[1], # Precisione per la classe positiva (1)\n",
    "        \"positive_recall\": recall[1],       # Recall per la classe positiva (1)\n",
    "        \"positive_f1\": f1[1],               # F1-score per la classe positiva (1)\n",
    "        \"negative_precision\": precision[0], # Precisione per la classe negativa (0)\n",
    "        \"negative_recall\": recall[0],       # Recall per la classe negativa (0)\n",
    "        \"negative_f1\": f1[0],               # F1-score per la classe negativa (0)\n",
    "        \"macro_f1\": np.mean([f1[0], f1[1]]) # Macro F1-score\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3abdbc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Definizione degli argomenti di training...\n",
      "TrainingArguments definiti.\n"
     ]
    }
   ],
   "source": [
    "# --- Instanziare un oggetto TrainingArguments ---\n",
    "print(\"\\nDefinizione degli argomenti di training...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Directory dove verranno salvati i checkpoint del modello e i risultati\n",
    "    eval_strategy='epoch',           # Esegue la valutazione alla fine di ogni epoca\n",
    "    num_train_epochs=3,              # Numero di epoche di training\n",
    "    per_device_train_batch_size=16,  # Dimensione del batch per training per GPU/CPU\n",
    "    per_device_eval_batch_size=64,   # Dimensione del batch per valutazione per GPU/CPU\n",
    "    warmup_steps=500,                # Numero di step di \"warmup\" per lo scheduler del learning rate\n",
    "    weight_decay=0.01,               # Peso per la regolarizzazione L2 (utile per prevenire overfitting)\n",
    "    logging_dir='./logs',            # Directory per i log di TensorBoard\n",
    "    logging_steps=500,               # Registra i log ogni 500 step\n",
    "    save_strategy=\"epoch\",           # Salva il modello alla fine di ogni epoca\n",
    "    load_best_model_at_end=True,     # Carica il miglior modello (basato su eval_strategy) alla fine del training\n",
    "    metric_for_best_model=\"accuracy\",# Specifica la metrica per determinare il \"miglior\" modello\n",
    "    report_to='none',                # Non inviare log a servizi esterni (es. wandb, mlflow)\n",
    "    fp16=False,                      # Imposta a True se hai una GPU compatibile per l'addestramento in mixed precision\n",
    ")\n",
    "print(\"TrainingArguments definiti.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02bba002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizializzazione del Trainer...\n",
      "Trainer inizializzato.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1257995/633860319.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# --- Instanziare un Trainer ---\n",
    "print(\"\\nInizializzazione del Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,                         # Il modello DistilBERT per la classificazione\n",
    "    args=training_args,                  # Gli argomenti di training definiti\n",
    "    train_dataset=tokenized_datasets['train'], # Il dataset di training tokenizzato\n",
    "    eval_dataset=tokenized_datasets['validation'], # Il dataset di validazione tokenizzato\n",
    "    data_collator=data_collator,         # Il data collator per la creazione dei batch\n",
    "    compute_metrics=compute_metrics,     # La funzione per calcolare le metriche di valutazione\n",
    "    tokenizer=tokenizer                  # Passiamo il tokenizer al Trainer per usi interni (es. logging)\n",
    ")\n",
    "print(\"Trainer inizializzato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f391156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avvio del fine-tuning (potrebbe richiedere tempo)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='801' max='801' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [801/801 38:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Positive F1</th>\n",
       "      <th>Negative Precision</th>\n",
       "      <th>Negative Recall</th>\n",
       "      <th>Negative F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.399236</td>\n",
       "      <td>0.826454</td>\n",
       "      <td>0.779743</td>\n",
       "      <td>0.909944</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.742964</td>\n",
       "      <td>0.810645</td>\n",
       "      <td>0.825236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.381858</td>\n",
       "      <td>0.826454</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.848030</td>\n",
       "      <td>0.830119</td>\n",
       "      <td>0.841176</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.822627</td>\n",
       "      <td>0.826373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.454157</td>\n",
       "      <td>0.849906</td>\n",
       "      <td>0.836036</td>\n",
       "      <td>0.870544</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.864971</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.846743</td>\n",
       "      <td>0.849842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning completato.\n",
      "\n",
      "Valutazione delle prestazioni sul set di test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risultati sul set di test dopo il fine-tuning:\n",
      "{'eval_loss': 0.5289661884307861, 'eval_accuracy': 0.8311444652908068, 'eval_positive_precision': 0.8203266787658802, 'eval_positive_recall': 0.8480300187617261, 'eval_positive_f1': 0.8339483394833949, 'eval_negative_precision': 0.8427184466019417, 'eval_negative_recall': 0.8142589118198874, 'eval_negative_f1': 0.8282442748091603, 'eval_macro_f1': 0.8310963071462776, 'eval_runtime': 19.9007, 'eval_samples_per_second': 53.566, 'eval_steps_per_second': 0.452, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report di classificazione dettagliato sul set di test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.83       533\n",
      "    positive       0.82      0.85      0.83       533\n",
      "\n",
      "    accuracy                           0.83      1066\n",
      "   macro avg       0.83      0.83      0.83      1066\n",
      "weighted avg       0.83      0.83      0.83      1066\n",
      "\n",
      "\n",
      "Comparazione con la baseline (accuracy del test set):\n",
      "- Baseline (SVM su feature estratte): circa 0.8068\n",
      "- Fine-tuned DistilBERT: 0.8311\n"
     ]
    }
   ],
   "source": [
    "# --- Chiamare trainer.train() e trainer.evaluate() ---\n",
    "print(\"\\nAvvio del fine-tuning (potrebbe richiedere tempo)...\")\n",
    "trainer.train()\n",
    "print(\"\\nFine-tuning completato.\")\n",
    "\n",
    "print(\"\\nValutazione delle prestazioni sul set di test...\")\n",
    "# Esegui la valutazione sul set di test, che non è stato usato durante l'addestramento\n",
    "test_results = trainer.evaluate(tokenized_datasets['test'])\n",
    "print(\"\\nRisultati sul set di test dopo il fine-tuning:\")\n",
    "print(test_results)\n",
    "\n",
    "# Per un report di classificazione più dettagliato sul set di test:\n",
    "# Ottieni le previsioni raw (logits) sul set di test\n",
    "predictions = trainer.predict(tokenized_datasets['test'])\n",
    "# Converti i logits in etichette predette\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "# Ottieni le etichette reali\n",
    "true_labels = tokenized_datasets['test']['label']\n",
    "\n",
    "print(\"\\nReport di classificazione dettagliato sul set di test:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=['negative', 'positive']))\n",
    "\n",
    "print(\"\\nComparazione con la baseline (accuracy del test set):\")\n",
    "print(f\"- Baseline (SVM su feature estratte): circa 0.8068\")\n",
    "print(f\"- Fine-tuned DistilBERT: {test_results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8376de-8554-4a13-aac3-59257f3eb3fd",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 3: Choose at Least One\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55cf4d-e64b-47fc-b8d5-37288b72d90d",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: Efficient Fine-tuning for Sentiment Analysis (easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f183856-1111-4fe9-81f1-691fe7c1b706",
   "metadata": {},
   "source": [
    "In Exercise 2 we fine-tuned the *entire* Distilbert model on Rotten Tomatoes. This is expensive, even for a small model. Find an *efficient* way to fine-tune Distilbert on the Rotten Tomatoes dataset (or some other dataset).\n",
    "\n",
    "**Hint**: You could check out the [HuggingFace PEFT library](https://huggingface.co/docs/peft/en/index) for some state-of-the-art approaches that should \"just work\". How else might you go about making fine-tuning more efficient without having to change your training pipeline from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ea6bca5-9b36-424e-898c-52c0777eae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4af14411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del dataset 'rotten_tomatoes'...\n",
      "Dataset caricato con successo!\n",
      "\n",
      "Caricamento del tokenizer 'distilbert-base-uncased'...\n",
      "Tokenizer caricato con successo!\n",
      "\n",
      "Applicazione della funzione di tokenizzazione al dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc599e010d2d4df6980f88fb47e05f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tokenizzato e trasformato.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'rotten_tomatoes'\n",
    "model_name = 'distilbert-base-uncased' \n",
    "num_labels = 2 \n",
    "\n",
    "print(f\"Caricamento del dataset '{dataset_name}'...\")\n",
    "dataset = load_dataset(dataset_name)\n",
    "print(\"Dataset caricato con successo!\")\n",
    "\n",
    "print(f\"\\nCaricamento del tokenizer '{model_name}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"Tokenizer caricato con successo!\")\n",
    "\n",
    "# Funzione di tokenizzazione (come nell'Esercizio 2.1)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "print(\"\\nApplicazione della funzione di tokenizzazione al dataset...\")\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "print(\"Dataset tokenizzato e trasformato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad8f80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caricamento del modello 'distilbert-base-uncased' per la classificazione di sequenze (num_labels=2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello base caricato con successo!\n"
     ]
    }
   ],
   "source": [
    "# --- Caricamento del modello base (come nell'Esercizio 2.2) ---\n",
    "print(f\"\\nCaricamento del modello '{model_name}' per la classificazione di sequenze (num_labels={num_labels})...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "print(\"Modello base caricato con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72095d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurazione e applicazione di PEFT (LoRA)...\n",
      "Modello trasformato in PEFT (LoRA) con successo.\n",
      "trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n"
     ]
    }
   ],
   "source": [
    "# --- Configurazione e applicazione di PEFT (LoRA) (Nuovo per l'Esercizio 3.1) ---\n",
    "print(\"\\nConfigurazione e applicazione di PEFT (LoRA)...\")\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"], # Moduli di attenzione in DistilBERT\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(\"Modello trasformato in PEFT (LoRA) con successo.\")\n",
    "model.print_trainable_parameters() # Mostra quanti parametri sono ora addestrabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9a8b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizializzazione del DataCollatorWithPadding...\n",
      "DataCollatorWithPadding inizializzato.\n"
     ]
    }
   ],
   "source": [
    "# --- Instanziare un DataCollatorWithPadding ---\n",
    "print(\"\\nInizializzazione del DataCollatorWithPadding...\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"DataCollatorWithPadding inizializzato.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038cdf6",
   "metadata": {},
   "source": [
    "Tutto il resto è già stato definito nel punto precendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f6922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avvio del fine-tuning con PEFT (potrebbe richiedere meno tempo)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='801' max='801' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [801/801 37:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Positive Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Positive F1</th>\n",
       "      <th>Negative Precision</th>\n",
       "      <th>Negative Recall</th>\n",
       "      <th>Negative F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.604171</td>\n",
       "      <td>0.843340</td>\n",
       "      <td>0.841418</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.843779</td>\n",
       "      <td>0.845283</td>\n",
       "      <td>0.840525</td>\n",
       "      <td>0.842897</td>\n",
       "      <td>0.843338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.549464</td>\n",
       "      <td>0.848968</td>\n",
       "      <td>0.838182</td>\n",
       "      <td>0.864916</td>\n",
       "      <td>0.851339</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.833021</td>\n",
       "      <td>0.846520</td>\n",
       "      <td>0.848930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.758060</td>\n",
       "      <td>0.851782</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>0.866792</td>\n",
       "      <td>0.853974</td>\n",
       "      <td>0.862669</td>\n",
       "      <td>0.836773</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.851749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning con PEFT completato.\n",
      "\n",
      "Valutazione delle prestazioni sul set di test con il modello PEFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risultati sul set di test dopo il fine-tuning con PEFT:\n",
      "{'eval_loss': 0.8086183667182922, 'eval_accuracy': 0.8348968105065666, 'eval_positive_precision': 0.8275229357798165, 'eval_positive_recall': 0.8461538461538461, 'eval_positive_f1': 0.8367346938775511, 'eval_negative_precision': 0.8426103646833013, 'eval_negative_recall': 0.8236397748592871, 'eval_negative_f1': 0.8330170777988615, 'eval_macro_f1': 0.8348758858382063, 'eval_runtime': 20.0158, 'eval_samples_per_second': 53.258, 'eval_steps_per_second': 0.45, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdonadio/miniconda3/envs/transformers/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report di classificazione dettagliato sul set di test (PEFT):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83       533\n",
      "    positive       0.83      0.85      0.84       533\n",
      "\n",
      "    accuracy                           0.83      1066\n",
      "   macro avg       0.84      0.83      0.83      1066\n",
      "weighted avg       0.84      0.83      0.83      1066\n",
      "\n",
      "\n",
      "Comparazione con le prestazioni precedenti (accuracy del test set):\n",
      "- Baseline (SVM su feature estratte): circa 0.8068\n",
      "- Fine-tuned DistilBERT (full): Il tuo risultato precedente (circa 0.8396 o 0.8321)\n",
      "- Fine-tuned DistilBERT (PEFT LoRA): 0.8349\n"
     ]
    }
   ],
   "source": [
    "# --- Avviare l'addestramento e la valutazione ---\n",
    "print(\"\\nAvvio del fine-tuning con PEFT (potrebbe richiedere meno tempo)...\")\n",
    "trainer.train()\n",
    "print(\"\\nFine-tuning con PEFT completato.\")\n",
    "\n",
    "print(\"\\nValutazione delle prestazioni sul set di test con il modello PEFT...\")\n",
    "test_results_peft = trainer.evaluate(tokenized_datasets['test'])\n",
    "print(\"\\nRisultati sul set di test dopo il fine-tuning con PEFT:\")\n",
    "print(test_results_peft)\n",
    "\n",
    "# Per un report di classificazione più dettagliato sul set di test:\n",
    "predictions_peft = trainer.predict(tokenized_datasets['test'])\n",
    "predicted_labels_peft = np.argmax(predictions_peft.predictions, axis=-1)\n",
    "true_labels_peft = tokenized_datasets['test']['label']\n",
    "\n",
    "print(\"\\nReport di classificazione dettagliato sul set di test (PEFT):\")\n",
    "print(classification_report(true_labels_peft, predicted_labels_peft, target_names=['negative', 'positive']))\n",
    "\n",
    "print(\"\\nComparazione con le prestazioni precedenti (accuracy del test set):\")\n",
    "print(f\"- Baseline (SVM su feature estratte): circa 0.8068\")\n",
    "# Usa l'accuracy del tuo fine-tuning precedente per il confronto diretto\n",
    "print(f\"- Fine-tuned DistilBERT (full): Il tuo risultato precedente (circa 0.8396 o 0.8321)\")\n",
    "print(f\"- Fine-tuned DistilBERT (PEFT LoRA): {test_results_peft['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1c4c9",
   "metadata": {},
   "source": [
    "## Commento sui Risultati\n",
    "Questi risultati sono molto positivi e confermano il valore delle tecniche *** PEFT ***.\n",
    "\n",
    "### Prestazioni Solide del Modello PEFT: \n",
    "Il modello fine-tuned con PEFT (LoRA) raggiunge un'accuratezza di circa 83.49%. \n",
    "\n",
    "### Efficienza con Prestazioni Competing: \n",
    "Ciò che rende questi risultati particolarmente impressionanti è che, pur addestrando solo una minuscola frazione dei parametri totali del modello (circa l'1%), le prestazioni sono quasi identiche a quelle del fine-tuning completo. La differenza rispetto al miglior risultato di fine-tuning completo (0.8396) è minima, di soli 0.0047.\n",
    "\n",
    "### Accuratezza e Metriche Bilanciate: \n",
    "Il modello continua a mostrare performance equilibrate tra le classi \"negative\" e \"positive\", con precisione, recall e F1-score che si aggirano intorno a 0.83−0.85. Questo significa che è altrettanto efficace nell'identificare entrambi i tipi di sentiment.\n",
    "\n",
    "In sintesi, si è dimostrato con successo che le tecniche di fine-tuning efficiente come PEFT (LoRA) permettono di ottenere prestazioni di alto livello, quasi indistinguibili da quelle del fine-tuning completo, ma con un costo computazionale e di memoria drasticamente ridotto. Questo è un vantaggio enorme in scenari reali, dove le risorse sono spesso limitate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da2e49",
   "metadata": {},
   "source": [
    "Perchè ci sono tanti **`UserWarning`**?\n",
    "\n",
    "L'output del modello è così \"compatto\" che non ha una dimensione aggiuntiva per essere direttamente \"impilato\". PyTorch risolve questo problema automaticamente facendo \"unsqueeze\" (aggiungendo una dimensione di grandezza 1) a questi scalari e poi raggruppandoli in un vettore.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
